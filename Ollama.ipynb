{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyME508Ry9q6cdNjxyrVtDOs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})"],"metadata":{"id":"MmsngdhSplq_","executionInfo":{"status":"ok","timestamp":1716140358572,"user_tz":-480,"elapsed":2,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install colab-xterm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"apwQVKlR0hP2","executionInfo":{"status":"ok","timestamp":1716236572358,"user_tz":-480,"elapsed":9916,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"cace9d26-8c87-4e73-80be-71600c49d760"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting colab-xterm\n","  Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n","Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.3)\n","Installing collected packages: colab-xterm\n","Successfully installed colab-xterm-0.2.0\n"]}]},{"cell_type":"code","source":["%load_ext colabxterm"],"metadata":{"id":"zCpyIuU01Bpu","executionInfo":{"status":"ok","timestamp":1716236575324,"user_tz":-480,"elapsed":454,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%xterm"],"metadata":{"id":"2noUFjEf1EXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! curl -fsSL https://ollama.com/install.sh | sed 's#https://ollama.com/download#https://github.com/jmorganca/ollama/releases/download/v0.1.27#' | sh"],"metadata":{"id":"O5lnmJbbSsB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nohup ollama serve &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTTOppbrmw0f","executionInfo":{"status":"ok","timestamp":1716141955306,"user_tz":-480,"elapsed":477,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"8b6cc3de-c499-4789-cb38-c651844d5ec7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"code","source":["!ollama pull llava &>/dev/null"],"metadata":{"id":"PbEZs_0onVbY","executionInfo":{"status":"ok","timestamp":1716146469764,"user_tz":-480,"elapsed":285,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!ollama pull mistral &>/dev/null"],"metadata":{"id":"QTZOAF2Ln4ZQ","executionInfo":{"status":"ok","timestamp":1716142132924,"user_tz":-480,"elapsed":64262,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!ollama list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JVb12ZvoKY3","executionInfo":{"status":"ok","timestamp":1716149909947,"user_tz":-480,"elapsed":284,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"a8d4a0b5-37f0-474a-c9ed-3d380a9810cb"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[GIN] 2024/05/19 - 20:18:29 | 200 |      31.266µs |       127.0.0.1 | HEAD     \"/\"\n","[GIN] 2024/05/19 - 20:18:29 | 200 |     544.247µs |       127.0.0.1 | GET      \"/api/tags\"\n","NAME         \tID          \tSIZE  \tMODIFIED       \n","llama2:latest\t78e26419b446\t3.8 GB\t12 minutes ago\t\n"]}]},{"cell_type":"code","source":["!ollama --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05FXIUdNmpax","executionInfo":{"status":"ok","timestamp":1716238223023,"user_tz":-480,"elapsed":285,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"46ccf32f-d221-460c-a185-77ff8a2d4150"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: ollama: command not found\n"]}]},{"cell_type":"code","source":["!pip install ngrok\n","!pip install pyngrok"],"metadata":{"id":"jqjSu782QDaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import threading\n","import time\n","import os\n","import asyncio\n","from pyngrok import ngrok\n","import threading\n","import queue\n","import time\n","from threading import Thread\n","\n","# Get your ngrok token from your ngrok account:\n","# https://dashboard.ngrok.com/get-started/your-authtoken\n","token=\"2ggno27BakF83etx7SZkZM7eHWE_4Pvjwv2LPvkytbiQEeXRV\"\n","ngrok.set_auth_token(token)\n","\n","# set up a stoppable thread (not mandatory, but cleaner if you want to stop this later\n","class StoppableThread(threading.Thread):\n","    def __init__(self, *args, **kwargs):\n","        super(StoppableThread, self).__init__(*args, **kwargs)\n","        self._stop_event = threading.Event()\n","\n","    def stop(self):\n","        self._stop_event.set()\n","\n","    def is_stopped(self):\n","        return self._stop_event.is_set()\n","\n","def start_ngrok(q, stop_event):\n","    try:\n","        # Start an HTTP tunnel on the specified port\n","        public_url = ngrok.connect(11434)\n","        # Put the public URL in the queue\n","        q.put(public_url)\n","        # Keep the thread alive until stop event is set\n","        while not stop_event.is_set():\n","            time.sleep(1)  # Adjust sleep time as needed\n","    except Exception as e:\n","        print(f\"Error in start_ngrok: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-Jqo78YQa1j","executionInfo":{"status":"ok","timestamp":1716149063558,"user_tz":-480,"elapsed":1029,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"36cbce4f-b4b1-41c0-d230-58e4cf7424f6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"code","source":["# Create a queue to share data between threads\n","url_queue = queue.Queue()\n","\n","# Start ngrok in a separate thread\n","ngrok_thread = StoppableThread(target=start_ngrok, args=(url_queue, StoppableThread.is_stopped))\n","ngrok_thread.start()"],"metadata":{"id":"A0VwP3obQtNk","executionInfo":{"status":"ok","timestamp":1716149072055,"user_tz":-480,"elapsed":3,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Wait for the ngrok tunnel to be established\n","while True:\n","    try:\n","        public_url = url_queue.get()\n","        if public_url:\n","            break\n","        print(\"Waiting for ngrok URL...\")\n","        time.sleep(1)\n","    except Exception as e:\n","        print(f\"Error in retrieving ngrok URL: {e}\")\n","\n","print(\"Ngrok tunnel established at:\", public_url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"593QBBTIQwgD","executionInfo":{"status":"ok","timestamp":1716149074306,"user_tz":-480,"elapsed":5,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}},"outputId":"126671e0-ed85-4e7e-c303-7bdf94a7cf5b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Ngrok tunnel established at: NgrokTunnel: \"https://06f8-34-138-186-132.ngrok-free.app\" -> \"http://localhost:11434\"\n"]}]},{"cell_type":"code","source":["import os\n","import asyncio\n","\n","# NB: You may need to set these depending and get cuda working depending which backend you are running.\n","# Set environment variable for NVIDIA library\n","# Set environment variables for CUDA\n","os.environ['PATH'] += ':/usr/local/cuda/bin'\n","# Set LD_LIBRARY_PATH to include both /usr/lib64-nvidia and CUDA lib directories\n","os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia:/usr/local/cuda/lib64'\n","\n","async def run_process(cmd):\n","    print('>>> starting', *cmd)\n","    process = await asyncio.create_subprocess_exec(\n","        *cmd,\n","        stdout=asyncio.subprocess.PIPE,\n","        stderr=asyncio.subprocess.PIPE\n","    )\n","\n","    # define an async pipe function\n","    async def pipe(lines):\n","        async for line in lines:\n","            print(line.decode().strip())\n","\n","        await asyncio.gather(\n","            pipe(process.stdout),\n","            pipe(process.stderr),\n","        )\n","\n","    # call it\n","    await asyncio.gather(pipe(process.stdout), pipe(process.stderr))"],"metadata":{"id":"AJM2B2EUQ4Cc","executionInfo":{"status":"ok","timestamp":1716149087800,"user_tz":-480,"elapsed":271,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import asyncio\n","import threading\n","\n","async def start_ollama_serve():\n","    await run_process(['ollama', 'serve'])\n","\n","def run_async_in_thread(loop, coro):\n","    asyncio.set_event_loop(loop)\n","    loop.run_until_complete(coro)\n","    loop.close()\n","\n","# Create a new event loop that will run in a new thread\n","new_loop = asyncio.new_event_loop()\n","\n","# Start ollama serve in a separate thread so the cell won't block execution\n","thread = threading.Thread(target=run_async_in_thread, args=(new_loop, start_ollama_serve()))\n","thread.start()"],"metadata":{"id":"M-sY5fGGQ8As"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! export OLLAMA_HOST=https://06f8-34-138-186-132.ngrok-free.app/"],"metadata":{"id":"FexmvZ9aRBjM","executionInfo":{"status":"ok","timestamp":1716149103784,"user_tz":-480,"elapsed":297,"user":{"displayName":"盧雯光","userId":"02117494503154262920"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!ollama pull llama2"],"metadata":{"id":"AT6z9qOzRJK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -X POST https://06f8-34-138-186-132.ngrok-free.app/api/generate -d '{ \"model\": \"llama2\", \"prompt\":\"Good Morning\" , \"stream\": false }'"],"metadata":{"id":"lGf2TTqeRN99"},"execution_count":null,"outputs":[]}]}